select(all_of(join_column_df1))
# 使用反引号处理包含特殊字符的列名
df2_selected <- df2 %>%
select(taxon, MI35, MI33, MI32, MI38, MI36, MI34, MI37,
MI27, MI28, MI29, MI31, MI17, MI21, MI20, MI24,
MI23, MI26, MI19, MI18, MI15, MI25, MI22, MI14,
MI16, MI1, MI2, MI3, MI4, MI5, MI6, MI7, MI8,
MI9, MI10, MI11, MI12, MI13, CON1, CON2, CON3,
CON4, CON5, CON6, CON7, CON8, CON9, CON10, CON11,
CON12, CON13, CON14, CON15, CON16, CON17, CON18,
CON19, CON20, CON21, CON22, CON23, CON24, CON25,
CON26, CON27, CON28, CON29, CON30, CON31, CON32,
CON33, CON34, CON35, CON36, CON37, CON38, CON39,
CON40, CON41, CON42, CON43, CON44, CON45, CON46,
CON47, `lfc_(Intercept)`, `lfc_GroupMI`, `se_(Intercept)`,
`se_GroupMI`, `W_(Intercept)`, `W_GroupMI`, `p_(Intercept)`,
`p_GroupMI`, `q_(Intercept)`, `q_GroupMI`, `diff_(Intercept)`,
`diff_GroupMI`, `passed_ss_(Intercept)`, `passed_ss_GroupMI`,
`diff_robust_(Intercept)`, `diff_robust_GroupMI`)
# 执行左连接
merged_df <- df2_selected %>%
left_join(df1_selected, by = c("taxon" = join_column_df1))
# 保存结果
write.xlsx(merged_df, output_path)
cat("文件拼接完成！\n")
cat("结果保存路径:", output_path, "\n")
cat("原始df2行数:", nrow(df2), "\n")
cat("合并后行数:", nrow(merged_df), "\n")
cat("列数:", ncol(merged_df), "\n")
# 加载必要的包
library(readxl)
library(dplyr)
library(openxlsx)
# 文件路径
file1_path <- "E:/Python/MI_Analysis/metagenome/data_figures/f/科水平.xlsx"
file2_path <- "E:/Python/MI_Analysis/metagenome/data_figures/f/MaAsLin2_OTU_new/virus/all_results.xlsx"
output_path <- "E:/Python/MI_Analysis/metagenome/data_figures/f/f_MaAsLin2_merged_result.xlsx"
# 读取两个Excel文件
df1 <- read_excel(file1_path)
df2 <- read_excel(file2_path)
# 查找匹配的列名
find_join_column <- function(df) {
# 查找包含vOTU的列名
vOTU_columns <- grep("vOTU", colnames(df), value = TRUE, ignore.case = TRUE)
if(length(vOTU_columns) > 0) {
return(vOTU_columns[1])
}
# 如果没有找到vOTU列，返回第一列
return(colnames(df)[1])
}
# 获取匹配列名
join_column_df1 <- find_join_column(df1)
cat("使用列进行匹配:", join_column_df1, "-> taxon\n")
# 选择需要的列
df1_selected <- df1 %>%
select(all_of(join_column_df1), MI35, MI33, MI32,
MI38, MI36, MI34, MI37, MI27, MI28, MI29, MI31,
MI17, MI21, MI20, MI24, MI23, MI26, MI19, MI18,
MI15, MI25, MI22, MI14, MI16, MI1, MI2, MI3,
MI4, MI5, MI6, MI7, MI8, MI9, MI10, MI11, MI12,
MI13, CON1, CON2, CON3, CON4, CON5, CON6, CON7,
CON8, CON9, CON10, CON11, CON12, CON13, CON14,
CON15, CON16, CON17, CON18, CON19, CON20, CON21,
CON22, CON23, CON24, CON25, CON26, CON27, CON28,
CON29, CON30, CON31, CON32, CON33, CON34, CON35,
CON36, CON37, CON38, CON39, CON40, CON41, CON42,
CON43, CON44, CON45, CON46, CON47)
# 使用反引号处理包含特殊字符的列名
df2_selected <- df2 %>%
select(feature, metadata, value, coef, stderr, N, N.not.0, pval, qval)
# 执行左连接
merged_df <- df2_selected %>%
left_join(df1_selected, by = c("feature" = join_column_df1))
# 保存结果
write.xlsx(merged_df, output_path)
cat("文件拼接完成！\n")
cat("结果保存路径:", output_path, "\n")
cat("原始df2行数:", nrow(df2), "\n")
cat("合并后行数:", nrow(merged_df), "\n")
cat("列数:", ncol(merged_df), "\n")
# =============================================================================
# 四类微生物 OTU 表 ANCOM-BC2 分析（包含原始丰度数据）
# =============================================================================
library(phyloseq)
library(ANCOMBC)
library(openxlsx)
# ----------------------------
# 1. 文件路径
# ----------------------------
otu_files <- list(
virus = "E:/Python/MI_Analysis/metagenome/data_figures/g/属水平.xlsx"
)
metadata_file = "E:/Python/MI_Analysis/metagenome/data_figures/g/sample_metadata.xlsx"
# 输出文件夹
output_dir <- "E:/Python/MI_Analysis/metagenome/data_figures/g/ancombc2_results_new/"
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
# ----------------------------
# 2. 读取元数据
# ----------------------------
metadata <- read.xlsx(metadata_file)
rownames(metadata) <- metadata$SampleID
# ----------------------------
# 循环分析四类微生物
# ----------------------------
for (microbe in names(otu_files)) {
cat("\n正在分析:", microbe, "\n")
# 读取 OTU 表
feature_data <- read.xlsx(otu_files[[microbe]], check.names = FALSE)
rownames(feature_data) <- feature_data$属
feature_data_only <- feature_data[, -1, drop = FALSE]  # 删除 ID 列，只保留丰度
cat("OTU总数:", nrow(feature_data_only), "\n")
# 打印 OTU ID 列前 6 行
cat("\n原始OTU ID前6行:\n")
print(head(feature_data$属, 6))
# ----------------------------
# 构建 phyloseq 对象
# ----------------------------
common_samples <- intersect(colnames(feature_data_only), metadata$SampleID)
feature_data_common <- feature_data_only[, common_samples, drop = FALSE]
metadata_common <- metadata[common_samples, , drop = FALSE]
rownames(metadata_common) <- metadata_common$SampleID
cat("共同样本数量:", length(common_samples), "\n")
# 检查是否有足够的样本
if (length(common_samples) < 3) {
cat("警告: 样本数量不足，跳过", microbe, "\n")
next
}
# 构建phyloseq对象时保留原始OTU ID作为行名
otu <- otu_table(as.matrix(feature_data_common), taxa_are_rows = TRUE)
sam <- sample_data(metadata_common)
ps_obj <- phyloseq(otu, sam)
# 保存原始OTU ID和丰度数据
original_taxon_names <- rownames(feature_data_common)
original_abundance_data <- feature_data_common
# ----------------------------
# 运行 ANCOM-BC2
# ----------------------------
ancombc_res <- tryCatch({
ancombc2(
data = ps_obj,
fix_formula = "Group",
p_adj_method = "fdr",
lib_cut = 0,
group = "Group",
struc_zero = FALSE,
neg_lb = TRUE,
alpha = 0.05,
n_cl = 6
)
}, error = function(e) {
cat(paste0("ANCOM-BC2分析出错: ", microbe, " - ", e$message, "\n"))
return(NULL)
})
# ----------------------------
# 处理结果 - 仅使用名称匹配方法
# ----------------------------
if (!is.null(ancombc_res)) {
res <- ancombc_res$res
# 添加ANCOM-BC2结果行数统计
cat("==========================================\n")
cat("ANCOM-BC2 结果统计 -", microbe, "\n")
cat("==========================================\n")
cat("原始输入OTU数量:     ", length(original_taxon_names), "\n")
cat("ANCOM-BC2结果OTU数量:", nrow(res), "\n")
cat("过滤掉的OTU数量:     ", length(original_taxon_names) - nrow(res), "\n")
cat("保留比例:            ", round(nrow(res)/length(original_taxon_names)*100, 2), "%\n")
# 检查行数是否匹配
if (nrow(res) != length(original_taxon_names)) {
cat("警告: ANCOM-BC2内部过滤了", length(original_taxon_names) - nrow(res), "个OTU\n")
}
# 使用名称匹配方法：检查ANCOM-BC2结果中的物种名称是否在原始名称中
matched_taxa <- intersect(original_taxon_names, res$taxon)
cat("通过名称匹配的物种数量:", length(matched_taxa), "\n")
if (length(matched_taxa) == nrow(res)) {
# 情况1: 所有结果物种都能在原始名称中找到
cat("情况1: 所有ANCOM-BC2结果物种都能匹配到原始名称\n")
final_res <- res
# 获取对应的丰度数据
abundance_data_to_add <- original_abundance_data[final_res$taxon, , drop = FALSE]
} else if (length(matched_taxa) > 0) {
# 情况2: 只有部分匹配，保留匹配的物种
cat("情况2: 只有部分物种匹配，保留", length(matched_taxa), "个匹配的物种\n")
final_res <- res[res$taxon %in% matched_taxa, ]
# 获取对应的丰度数据
abundance_data_to_add <- original_abundance_data[final_res$taxon, , drop = FALSE]
} else {
# 情况3: 如果完全无法匹配，使用原始名称（按顺序）
cat("情况3: 无法通过名称匹配，使用顺序映射\n")
final_res <- res
final_res$taxon <- original_taxon_names[1:nrow(res)]
# 获取对应的丰度数据
abundance_data_to_add <- original_abundance_data[final_res$taxon, , drop = FALSE]
}
# 将丰度数据插入到taxon列之后
cat("正在合并丰度数据...\n")
# 找到taxon列的位置
taxon_col_index <- which(colnames(final_res) == "taxon")
# 将结果表分成两部分：taxon列之前和之后
before_taxon <- final_res[, 1:taxon_col_index, drop = FALSE]
after_taxon <- final_res[, (taxon_col_index + 1):ncol(final_res), drop = FALSE]
# 合并：taxon列之前 + 丰度数据 + taxon列之后
final_res_with_abundance <- cbind(
before_taxon,
abundance_data_to_add,
after_taxon
)
# 保持原始样本名称，不添加前缀
# 丰度数据列名保持不变
cat("丰度数据已成功插入，新增", ncol(abundance_data_to_add), "个丰度列\n")
# 打印最终结果的前6行（只显示前几列以免输出过长）
cat("\n最终结果前6行（显示前8列）:\n")
print(head(final_res_with_abundance[, 1:min(8, ncol(final_res_with_abundance))], 6))
# 保存为 Excel
output_file <- paste0(output_dir, microbe, "_ANCOMBC2_results.xlsx")
wb <- createWorkbook()
addWorksheet(wb, "Complete_Results")
writeData(wb, "Complete_Results", final_res_with_abundance)
saveWorkbook(wb, output_file, overwrite = TRUE)
cat("==========================================\n")
cat(paste0("ANCOM-BC2结果已保存: ", output_file, "\n"))
cat(paste0("结果表维度: ", nrow(final_res_with_abundance), " 行, ", ncol(final_res_with_abundance), " 列\n"))
cat("其中包含", ncol(abundance_data_to_add), "个样本的丰度数据\n")
cat("==========================================\n\n")
} else {
cat("==========================================\n")
cat(paste0("ANCOM-BC2分析结果为空: ", microbe, "\n"))
cat("==========================================\n\n")
}
}
# 最终总结
cat("\n\n==========================================\n")
cat("所有分析完成! 总结:\n")
cat("==========================================\n")
for (microbe in names(otu_files)) {
output_file <- paste0(output_dir, microbe, "_ANCOMBC2_results.xlsx")
if (file.exists(output_file)) {
wb <- loadWorkbook(output_file)
sheet_data <- readWorkbook(wb, sheet = 1)
# 计算丰度数据列数（统计结果列通常有固定名称，其他列为丰度数据）
stat_columns <- c("taxon", "lfc_Group", "se_Group", "W_Group", "p_Group", "q_Group", "diff_Group")
abundance_cols <- ncol(sheet_data) - length(intersect(colnames(sheet_data), stat_columns))
cat(microbe, ": ", nrow(sheet_data), "行结果, ", abundance_cols, "个样本的丰度数据\n")
} else {
cat(microbe, ": 文件不存在\n")
}
}
cat("==========================================\n")
# =============================================================================
# 论文级 MaAsLin2 分析：病毒/古菌/细菌/真菌
# 自动 CSV→TSV、Excel→TSV，筛选 q<0.05 & |log2FC|>1，合并显著结果并标注升降趋势
# 修复特征名中的括号问题
# =============================================================================
rm(list = ls())
# ----------------------------
# 1. 安装依赖及 MaAsLin2（如果没有）
# ----------------------------
if (!requireNamespace("Maaslin2", quietly = TRUE)) {
if (!requireNamespace("remotes", quietly = TRUE)) install.packages("remotes")
deps <- c("dplyr", "data.table", "ggplot2", "Rcpp", "tibble", "stringr", "reshape2")
for (pkg in deps) if (!requireNamespace(pkg, quietly = TRUE)) install.packages(pkg)
remotes::install_github("biobakery/Maaslin2")
}
library(Maaslin2)
if (!requireNamespace("readxl", quietly = TRUE)) install.packages("readxl")
library(readxl)
library(dplyr)
# ----------------------------
# 2. 定义修复函数
# ----------------------------
repair_maaslin_output <- function(output_dir, original_features) {
# 修复 significant_results.tsv
sig_file <- file.path(output_dir, "significant_results.tsv")
if (file.exists(sig_file)) {
sig_df <- read.delim(sig_file, check.names = FALSE, stringsAsFactors = FALSE)
if (nrow(sig_df) > 0) {
# 创建特征名映射
feature_map <- data.frame(
cleaned = make.names(original_features, unique = TRUE),
original = as.character(original_features),
stringsAsFactors = FALSE
)
# 修复特征名
sig_df <- sig_df %>%
left_join(feature_map, by = c("feature" = "cleaned")) %>%
mutate(feature = ifelse(!is.na(original), original, feature)) %>%
select(-original)
# 保存修复后的文件
write.table(sig_df, sig_file, sep = "\t", row.names = FALSE, quote = FALSE)
cat("✅ 已修复", nrow(sig_df), "个特征名在", basename(sig_file), "\n")
}
}
# 修复 all_results.tsv
all_file <- file.path(output_dir, "all_results.tsv")
if (file.exists(all_file)) {
all_df <- read.delim(all_file, check.names = FALSE, stringsAsFactors = FALSE)
if (nrow(all_df) > 0) {
# 创建特征名映射
feature_map <- data.frame(
cleaned = make.names(original_features, unique = TRUE),
original = as.character(original_features),
stringsAsFactors = FALSE
)
# 修复特征名
all_df <- all_df %>%
left_join(feature_map, by = c("feature" = "cleaned")) %>%
mutate(feature = ifelse(!is.na(original), original, feature)) %>%
select(-original)
# 保存修复后的文件
write.table(all_df, all_file, sep = "\t", row.names = FALSE, quote = FALSE)
cat("✅ 已修复", nrow(all_df), "个特征名在", basename(all_file), "\n")
}
}
}
# ----------------------------
# 3. 文件路径
# ----------------------------
files <- list(
virus = "E:/Python/MI_Analysis/metagenome/data_figures/g/属水平.xlsx"
)
metadata_file <- "E:/Python/MI_Analysis/metagenome/data_figures/g/sample_metadata.xlsx"
outdir <- "E:/Python/MI_Analysis/metagenome/data_figures/g/MaAsLin2_OTU_new/"
if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
# ----------------------------
# 4. 读取 metadata 并保存为 TSV
# ----------------------------
metadata <- read_excel(metadata_file)
colnames(metadata)[1] <- "SampleID"
metadata_tsv <- file.path(outdir, "metadata_temp.tsv")
write.table(metadata, metadata_tsv, sep = "\t", row.names = FALSE, quote = FALSE)
# ----------------------------
# 5. 批量分析 + CSV → TSV 自动转换 + 筛选显著
# ----------------------------
all_sig_list <- list()  # 用于存储每类微生物的显著结果
for (microbe in names(files)) {
cat("\n=========== 开始分析:", microbe, "===========\n")
# 读取 Excel 文件
feature <- read_excel(files[[microbe]])
# 保存原始特征名（假设第一列是特征名）
if (!colnames(feature)[1] %in% c("Feature", "OTU", "Taxonomy")) {
colnames(feature)[1] <- "Feature"
}
original_features <- feature[[1]]
# 转换为 TSV 临时文件，禁用列名检查以保持原列名
feature_tsv <- file.path(outdir, paste0(microbe, "_temp.tsv"))
write.table(feature, feature_tsv, sep = "\t", row.names = FALSE, quote = FALSE, col.names = TRUE)
# 创建输出目录
outdir_microbe <- file.path(outdir, microbe)
if (!dir.exists(outdir_microbe)) dir.create(outdir_microbe)
# 运行 MaAsLin2（论文建议 q ≤ 0.05）
Maaslin2(
input_data = feature_tsv,
input_metadata = metadata_tsv,
output = outdir_microbe,
fixed_effects = c("Group"),
normalization = "TSS",
transform = "LOG",
analysis_method = "LM",
max_significance = 0.05
)
# ----------------------------
# 修复 MaAsLin2 输出文件中的特征名
# ----------------------------
cat("🔧 修复特征名中的括号问题...\n")
repair_maaslin_output(outdir_microbe, original_features)
# ----------------------------
# 读取显著结果并筛选 q<0.05 & |log2FC|>1
# ----------------------------
sig_file <- file.path(outdir_microbe, "significant_results.tsv")
if (file.exists(sig_file)) {
sig_df <- read.delim(sig_file, check.names = FALSE, stringsAsFactors = FALSE)
if (nrow(sig_df) > 0) {
# 使用 coef 近似 log2FC（如果 MaAsLin2 已经输出 log2FC，可改用 log2FC 列）
sig_df$log2FC <- sig_df$coef
# 筛选条件
sig_df <- sig_df %>% filter(qval < 0.05 & abs(log2FC) > 1)
if (nrow(sig_df) > 0) {
# 标注升降趋势
sig_df$Trend <- ifelse(sig_df$log2FC > 0, "Up", "Down")
sig_df$MicrobeClass <- microbe
all_sig_list[[microbe]] <- sig_df
# 显示修复后的特征名
cat("✅ ", microbe, "显著 feature 数量（q<0.05 & |log2FC|>1）：", nrow(sig_df), "\n")
cat("📝 显著特征名：", paste(sig_df$feature, collapse = ", "), "\n")
} else {
cat("⚠️ ", microbe, "没有满足 q<0.05 & |log2FC|>1 的 feature\n")
}
} else {
cat("⚠️ ", microbe, "没有显著 feature\n")
}
} else {
cat("⚠️ ", microbe, "显著结果文件不存在\n")
}
}
# ----------------------------
# 6. 合并四类微生物显著结果并保存
# ----------------------------
if (length(all_sig_list) > 0) {
combined_sig <- bind_rows(all_sig_list)
combined_file <- file.path(outdir, "combined_significant_results_q0.05_log2fc1.tsv")
write.table(combined_sig, combined_file, sep = "\t", row.names = FALSE, quote = FALSE)
cat("\n🎉 合并后的显著结果保存在：", combined_file, "\n")
cat("📊 总显著特征数量：", nrow(combined_sig), "\n")
} else {
cat("\n⚠️ 所有微生物类没有显著 feature，未生成合并表\n")
}
cat("\n🎉 所有分析完成！结果保存在：", outdir, "\n")
# 加载必要的包
library(readxl)
library(dplyr)
library(openxlsx)
# 文件路径
file1_path <- "E:/Python/MI_Analysis/metagenome/data_figures/g/属水平.xlsx"
file2_path <- "E:/Python/MI_Analysis/metagenome/data_figures/g/ancombc2_results_new/virus_ANCOMBC2_results.xlsx"
output_path <- "E:/Python/MI_Analysis/metagenome/data_figures/g/g_ANCOM-BC2_merged_result.xlsx"
# 读取两个Excel文件
df1 <- read_excel(file1_path)
df2 <- read_excel(file2_path)
# 查找匹配的列名
find_join_column <- function(df) {
# 查找包含vOTU的列名
vOTU_columns <- grep("vOTU", colnames(df), value = TRUE, ignore.case = TRUE)
if(length(vOTU_columns) > 0) {
return(vOTU_columns[1])
}
# 如果没有找到vOTU列，返回第一列
return(colnames(df)[1])
}
# 获取匹配列名
join_column_df1 <- find_join_column(df1)
cat("使用列进行匹配:", join_column_df1, "-> taxon\n")
# 选择需要的列
df1_selected <- df1 %>%
select(all_of(join_column_df1))
# 使用反引号处理包含特殊字符的列名
df2_selected <- df2 %>%
select(taxon, MI35, MI33, MI32, MI38, MI36, MI34, MI37,
MI27, MI28, MI29, MI31, MI17, MI21, MI20, MI24,
MI23, MI26, MI19, MI18, MI15, MI25, MI22, MI14,
MI16, MI1, MI2, MI3, MI4, MI5, MI6, MI7, MI8,
MI9, MI10, MI11, MI12, MI13, CON1, CON2, CON3,
CON4, CON5, CON6, CON7, CON8, CON9, CON10, CON11,
CON12, CON13, CON14, CON15, CON16, CON17, CON18,
CON19, CON20, CON21, CON22, CON23, CON24, CON25,
CON26, CON27, CON28, CON29, CON30, CON31, CON32,
CON33, CON34, CON35, CON36, CON37, CON38, CON39,
CON40, CON41, CON42, CON43, CON44, CON45, CON46,
CON47, `lfc_(Intercept)`, `lfc_GroupMI`, `se_(Intercept)`,
`se_GroupMI`, `W_(Intercept)`, `W_GroupMI`, `p_(Intercept)`,
`p_GroupMI`, `q_(Intercept)`, `q_GroupMI`, `diff_(Intercept)`,
`diff_GroupMI`, `passed_ss_(Intercept)`, `passed_ss_GroupMI`,
`diff_robust_(Intercept)`, `diff_robust_GroupMI`)
# 执行左连接
merged_df <- df2_selected %>%
left_join(df1_selected, by = c("taxon" = join_column_df1))
# 保存结果
write.xlsx(merged_df, output_path)
cat("文件拼接完成！\n")
cat("结果保存路径:", output_path, "\n")
cat("原始df2行数:", nrow(df2), "\n")
cat("合并后行数:", nrow(merged_df), "\n")
cat("列数:", ncol(merged_df), "\n")
# 加载必要的包
library(readxl)
library(dplyr)
library(openxlsx)
# 文件路径
file1_path <- "E:/Python/MI_Analysis/metagenome/data_figures/g/属水平.xlsx"
file2_path <- "E:/Python/MI_Analysis/metagenome/data_figures/g/MaAsLin2_OTU_new/virus/all_results.xlsx"
output_path <- "E:/Python/MI_Analysis/metagenome/data_figures/g/g_MaAsLin2_merged_result.xlsx"
# 读取两个Excel文件
df1 <- read_excel(file1_path)
df2 <- read_excel(file2_path)
# 查找匹配的列名
find_join_column <- function(df) {
# 查找包含vOTU的列名
vOTU_columns <- grep("vOTU", colnames(df), value = TRUE, ignore.case = TRUE)
if(length(vOTU_columns) > 0) {
return(vOTU_columns[1])
}
# 如果没有找到vOTU列，返回第一列
return(colnames(df)[1])
}
# 获取匹配列名
join_column_df1 <- find_join_column(df1)
cat("使用列进行匹配:", join_column_df1, "-> taxon\n")
# 选择需要的列
df1_selected <- df1 %>%
select(all_of(join_column_df1), MI35, MI33, MI32,
MI38, MI36, MI34, MI37, MI27, MI28, MI29, MI31,
MI17, MI21, MI20, MI24, MI23, MI26, MI19, MI18,
MI15, MI25, MI22, MI14, MI16, MI1, MI2, MI3,
MI4, MI5, MI6, MI7, MI8, MI9, MI10, MI11, MI12,
MI13, CON1, CON2, CON3, CON4, CON5, CON6, CON7,
CON8, CON9, CON10, CON11, CON12, CON13, CON14,
CON15, CON16, CON17, CON18, CON19, CON20, CON21,
CON22, CON23, CON24, CON25, CON26, CON27, CON28,
CON29, CON30, CON31, CON32, CON33, CON34, CON35,
CON36, CON37, CON38, CON39, CON40, CON41, CON42,
CON43, CON44, CON45, CON46, CON47)
# 使用反引号处理包含特殊字符的列名
df2_selected <- df2 %>%
select(feature, metadata, value, coef, stderr, N, N.not.0, pval, qval)
# 执行左连接
merged_df <- df2_selected %>%
left_join(df1_selected, by = c("feature" = join_column_df1))
# 保存结果
write.xlsx(merged_df, output_path)
cat("文件拼接完成！\n")
cat("结果保存路径:", output_path, "\n")
cat("原始df2行数:", nrow(df2), "\n")
cat("合并后行数:", nrow(merged_df), "\n")
cat("列数:", ncol(merged_df), "\n")
